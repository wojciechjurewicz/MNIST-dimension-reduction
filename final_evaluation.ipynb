{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data/processed_data.npz')\n",
    "X_train_img = data['X_train_img']\n",
    "y_train = data['y_train']\n",
    "X_test_img = data['X_test_img']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (784 dims) - Accuracy: 0.9692\n"
     ]
    }
   ],
   "source": [
    "# Load Baseline\n",
    "with open('results/baseline_metrics.txt', 'r') as f:\n",
    "    content = f.read().strip().split(',')\n",
    "    base_acc = float(content[0])\n",
    "    base_time = float(content[1])\n",
    "\n",
    "print(f\"Baseline (784 dims) - Accuracy: {base_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded.\n"
     ]
    }
   ],
   "source": [
    "# Model Definition & Loading\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.Flatten(), nn.Linear(32 * 7 * 7, latent_dim), nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_fc = nn.Linear(latent_dim, 32 * 7 * 7)\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.Unflatten(1, (32, 7, 7)),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        x_recon = self.decoder_fc(encoded)\n",
    "        decoded = self.decoder_conv(x_recon)\n",
    "        return decoded, encoded\n",
    "\n",
    "BEST_DIM = 32\n",
    "model = torch.load(f'models/conv_ae_{BEST_DIM}.pth', map_location=device, weights_only=False)\n",
    "model.eval()\n",
    "print(\"Model Loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing dataset...\n",
      "Encoded Shape: (60000, 32)\n"
     ]
    }
   ],
   "source": [
    "# Compress Data (Inference)\n",
    "print(\"Compressing dataset...\")\n",
    "start_encode = time.time()\n",
    "\n",
    "def get_latent_vectors(data_arr, batch_size=512):\n",
    "    tensor_data = torch.Tensor(data_arr)\n",
    "    loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(tensor_data), batch_size=batch_size)\n",
    "    latents = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            inputs = batch[0].to(device)\n",
    "            \n",
    "            # The forward method returns (decoded, encoded)\n",
    "            # We only care about 'encoded' (the latent vector)\n",
    "            _, encoded = model(inputs)\n",
    "            \n",
    "            latents.append(encoded.cpu().numpy())\n",
    "            \n",
    "    return np.vstack(latents)\n",
    "\n",
    "X_train_encoded = get_latent_vectors(X_train_img)\n",
    "X_test_encoded = get_latent_vectors(X_test_img)\n",
    "\n",
    "print(f\"Encoded Shape: {X_train_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest on PyTorch-Compressed Data...\n",
      "\n",
      "--- PYTORCH RESULTS ---\n",
      "Metric               | Original   | Compressed\n",
      "---------------------------------------------\n",
      "Accuracy             | 0.9692     | 0.9560\n",
      "Training Time (s)    | 3.34      | 2.23\n",
      "Dimensions           | 784        | 32\n",
      "Compression          | 1.0x       | 24.5x\n"
     ]
    }
   ],
   "source": [
    "# Train Classifier & Evaluate\n",
    "print(f\"Training Random Forest on PyTorch-Compressed Data...\")\n",
    "start_train = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "clf.fit(X_train_encoded, y_train)\n",
    "\n",
    "compressed_time = time.time() - start_train\n",
    "y_pred = clf.predict(X_test_encoded)\n",
    "compressed_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Stats\n",
    "original_size = 784 * 4\n",
    "compressed_size = BEST_DIM * 4\n",
    "reduction_ratio = original_size / compressed_size\n",
    "\n",
    "print(\"\\n--- PYTORCH RESULTS ---\")\n",
    "print(f\"{'Metric':<20} | {'Original':<10} | {'Compressed':<10}\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"{'Accuracy':<20} | {base_acc:.4f}     | {compressed_acc:.4f}\")\n",
    "print(f\"{'Training Time (s)':<20} | {base_time:.2f}      | {compressed_time:.2f}\")\n",
    "print(f\"{'Dimensions':<20} | {784}        | {BEST_DIM}\")\n",
    "print(f\"{'Compression':<20} | 1.0x       | {reduction_ratio:.1f}x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
